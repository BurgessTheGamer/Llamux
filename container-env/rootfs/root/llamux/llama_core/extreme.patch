--- main.c.orig
+++ main.c
@@ -227,7 +227,7 @@
     } else {
         pr_warn("ðŸ¦™ Llamux: No reserved memory, using vmalloc fallback\n");
         /* Fallback to vmalloc for testing */
-        size_t alloc_size = 64 * 1024 * 1024; /* 64MB for testing */
+        size_t alloc_size = 512ULL * 1024ULL * 1024ULL; /* 512MB - more reasonable */
         pr_info("ðŸ¦™ Llamux: Attempting to allocate %zu MB with vmalloc\n", alloc_size / (1024 * 1024));
         llama_state.model_memory = vmalloc(alloc_size);
         if (!llama_state.model_memory) {
@@ -241,8 +241,8 @@
     }
     
     /* Try to load model from firmware */
-    ret = -ENOENT; /* Pretend file not found */
-    fw = NULL;
+    ret = request_firmware(&fw, "llamux/tinyllama.gguf", NULL);
+    /* fw = NULL; */
     if (ret == 0) {
         pr_info("ðŸ¦™ Llamux: Found model file, size: %zu MB\n", fw->size / (1024*1024));
         
@@ -313,7 +313,7 @@
         }
         
         /* For now, limit tensor loading to prevent memory issues */
-        size_t max_tensor_size = 64 * 1024 * 1024; /* 64MB limit for testing */
+        size_t max_tensor_size = 256ULL * 1024ULL * 1024ULL; /* 256MB limit */
         size_t total_loaded = 0;
         
         pr_info("ðŸ¦™ Llamux: Loading model tensors (limited to %zu MB)...\n", 
